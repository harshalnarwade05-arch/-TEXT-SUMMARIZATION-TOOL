# -TEXT-SUMMARIZATION-TOOL
*COMPANY* : CODTECH IT SOLUTIONS
*NAME* : HARSHAL SUNIL NARWADE
*INTERN ID*:CTIS2569
*DOMAIN*:Artificial Intelligence
*DURATION*:4 WEEKS
*MENTOR*:Neela Santhosh Kumar  
Here is a **clear, professional 500+ word description** of your code that you can directly submit in your internship report:

---

## Description of the Text Summarization Code

The given Python program implements an extractive text summarization system using Natural Language Processing (NLP) techniques. The main objective of this code is to automatically generate a concise summary from a longer piece of text by selecting the most important sentences. This approach is based on statistical analysis rather than deep learning, making it efficient, lightweight, and suitable for academic and internship-level projects.

The program begins by importing three essential libraries: `numpy`, `re`, and `TfidfVectorizer` from `sklearn.feature_extraction.text`. NumPy is used for numerical operations, particularly for handling arrays and calculating sentence scores. The `re` module (regular expressions) is used to split the input paragraph into individual sentences. The `TfidfVectorizer` is a key component of the program, as it converts textual data into numerical format using the TF-IDF technique.

The core function in the program is `summarize_text(text, num_sentences=3)`. This function takes two parameters: the input text that needs to be summarized and the number of sentences required in the final summary. By default, the function returns three sentences unless specified otherwise.

Inside the function, the first step is sentence tokenization. This is done using a regular expression:

```
re.split(r'(?<=[.!?])\s+', text.strip())
```

This expression splits the paragraph into separate sentences whenever it encounters punctuation marks such as a period (.), exclamation mark (!), or question mark (?), followed by whitespace. The `strip()` function removes unnecessary leading and trailing spaces from the input text.

After splitting the text into sentences, the program checks whether the total number of sentences is less than or equal to the requested summary length. If so, it simply returns the original text, as summarization would not be necessary.

Next, the program applies the TF-IDF (Term Frequency–Inverse Document Frequency) method using `TfidfVectorizer`. TF-IDF is a widely used technique in Natural Language Processing for measuring the importance of words in a document relative to a collection of documents. In this case, each sentence is treated as a separate document. The vectorizer removes common English stop words such as “is,” “the,” and “and” to improve relevance. It then converts the sentences into a matrix of TF-IDF scores.

Once the TF-IDF matrix is created, the program calculates the importance score for each sentence. This is done by summing the TF-IDF values of all words in a sentence:

```
sentence_scores = np.asarray(tfidf_matrix.sum(axis=1)).flatten()
```

The higher the score, the more important the sentence is considered. These scores are stored in a NumPy array for easy manipulation.

The program then selects the indices of the top-scoring sentences using:

```
top_indices = sentence_scores.argsort()[-num_sentences:]
```

This line sorts the sentence scores and selects the highest ones based on the number of sentences requested. The selected indices are then sorted to maintain the original order of sentences in the text, ensuring that the summary remains coherent and readable.

Finally, the summary is generated by joining the selected sentences into a single string:

```
summary = " ".join(sentences[i] for i in top_indices)
```

The function returns this summary.

In the main part of the program, a sample paragraph about Natural Language Processing is provided as input. The function is called with `num_sentences=2`, meaning the summary will consist of two key sentences. The program then prints both the original text and the generated summary for comparison.

Overall, this code demonstrates a practical implementation of extractive text summarization using TF-IDF scoring. It is efficient, easy to understand, and suitable for handling moderate-sized text documents. The approach avoids complex neural networks while still producing meaningful summaries, making it ideal for educational purposes and introductory NLP projects.

---
*OUTPUT*:
<img width="1283" height="596" alt="Image" src="https://github.com/user-attachments/assets/8eb4715e-b589-46b7-bdda-8d73db0e8307" />

 
